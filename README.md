# classic-ml-practicum

Набор учебных проектов по **классическим методам машинного обучения**.  
Репозиторий содержит три законченных примера: от постановки задачи и подготовки данных до обучения моделей, оценки качества и визуализации результатов.

## Содержание

- `notebooks/01_fake_news_detection.ipynb` – определение фейковых новостей (TF-IDF + PassiveAggressiveClassifier)
- `notebooks/02_parkinsons_xgboost.ipynb` – обнаружение болезни Паркинсона (XGBoost)
- `notebooks/03_student_exam_success.ipynb` – прогноз успешной сдачи экзамена (Random Forest)
- `data/` – используемые датасеты (или инструкция по их загрузке)
- `requirements.txt` – список Python-зависимостей

---

## Технологии

- Python 3.x  
- `pandas`, `numpy`
- `scikit-learn`
- `matplotlib`, `seaborn`
- `xgboost`
- Jupyter / Google Colab

---

## Установка и запуск

```bash
# 1. Клонировать репозиторий
git clone https://github.com/disa-ufa/classic-ml-practicum.git
cd classic-ml-practicum

# 2. (Рекомендуется) создать виртуальное окружение
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux / macOS

# 3. Установить зависимости
pip install -r requirements.txt


Проект 1 — Обнаружение фейковых новостей
Ноутбук: notebooks/01_fake_news_detection.ipynb
Цель: по тексту новости определить, является ли она REAL или FAKE.
Основные шаги
Загрузка и первичный анализ датасета (распределение классов, длина текстов).
Разделение выборки на train/test.
Векторизация текста с помощью TfidfVectorizer:
очистка текста;
представление новостей в виде TF-IDF-признаков.
Обучение модели PassiveAggressiveClassifier.

Оценка качества:
accuracy на тестовой выборке;
матрица ошибок (confusion matrix);
визуализация результатов.

Результат
Модель показывает точность выше 90 % на тестовой выборке и хорошо отделяет реальные новости от фейковых.
Матрица ошибок и графики позволяют увидеть, сколько новостей ошибочно классифицируются в каждый из классов.

Проект 2 — Обнаружение болезни Паркинсона (XGBoost)
Ноутбук: notebooks/02_parkinsons_xgboost.ipynb
Датасет: UCI ML Parkinsons (акустические признаки речи пациентов).
Цель: по набору голосовых и статистических характеристик предсказать наличие/отсутствие болезни Паркинсона.

Основные шаги
Загрузка данных (parkinsons.data), обзор признаков, проверка пропусков.
Разделение на признаки X и целевую переменную y = status.
Train/Test-split в пропорции 80 % / 20 % с сохранением баланса классов (stratify).
Масштабирование признаков с помощью StandardScaler.
Обучение модели XGBClassifier:
настройка базовых гиперпараметров (число деревьев, глубина, скорость обучения и др.).

Оценка качества:
accuracy на тестовой выборке;
подробный classification_report (precision/recall/F1);
матрица ошибок (confusion matrix) с визуализацией через seaborn.heatmap.

Результат
Модель XGBoost достигает точности ≈ 92 % на тестовой выборке.
Баланс precision/recall показывает, что модель достаточно уверенно отличает пациентов с Паркинсоном от здоровых, при этом количество ложных отрицаний (пропущенных заболевших) минимально.

Проект 3 — Прогноз успешной сдачи экзамена

Ноутбук: notebooks/03_student_exam_success.ipynb
Датасет: Student Performance Data Set (успеваемость школьников по математике).
Цель: по социально-демографическим характеристикам и предыдущим оценкам предсказать, сдаст ли ученик финальный экзамен.

Основные шаги
Загрузка датасета student-mat.csv, первичный EDA:
распределение итоговой оценки G3;
анализ бинарной переменной passed (1 — сдал, 0 — нет).

Предобработка:
создание целевой переменной passed по порогу G3 (например, G3 >= 10);
кодирование категориальных признаков (get_dummies / One-Hot Encoding).
Разделение на train/test.
Обучение модели RandomForestClassifier (классический ансамблевый метод).
Оценка качества (accuracy, classification_report).

Визуализация:
распределение оценок G3 и классов passed;
важность признаков (feature_importances_) и бар-чарт топ-признаков.
